apiVersion: v1
kind: ConfigMap
metadata:
  name: kindlingcfg
  namespace: kindling 
data:
  kindling-collector-config.yml: |
    receivers:
      cgoreceiver:
        subscribe:
          - name: syscall_exit-writev
            category: net
          - name: syscall_exit-readv
            category: net
          - name: syscall_exit-write
            category: net
          - name: syscall_exit-read
            category: net
          - name: syscall_exit-sendto
            category: net
          - name: syscall_exit-recvfrom
            category: net
          - name: syscall_exit-sendmsg
            category: net
          - name: syscall_exit-recvmsg
            category: net
          - name: kprobe-tcp_close
          - name: kprobe-tcp_rcv_established
          - name: kprobe-tcp_drop
          - name: kprobe-tcp_retransmit_skb
          - name: syscall_exit-connect
          - name: kretprobe-tcp_connect
          - name: kprobe-tcp_set_state
    analyzers:
      tcpconnectanalyzer:
        channel_size: 10000
        wait_event_second: 10
        # Whether add pid and command info in tcp-connect-metrics's labels
        need_process_info: false
      tcpmetricanalyzer:
      networkanalyzer:
        connect_timeout: 100
        # How many seconds to wait until we consider a request as no response.
        request_timeout: 60
        # How many milliseconds to wait until we consider a request-response as slow.
        response_slow_threshold: 500
        # Whether enable conntrack module to find pod's ip when calling service
        enable_conntrack: true
        conntrack_max_state_size: 131072
        conntrack_rate_limit: 500
        proc_root: /proc
        # The protocol parsers which is enabled
        # When dissectors are enabled, agent will analyze the payload and enrich metric/trace with its content.
        protocol_parser: [ http, mysql, dns, redis, kafka ]
        # Which URL clustering method should be used to shorten the URL of HTTP request.
        # This is useful for decrease the cardinality of URLs.
        # Valid values: ["noparam", "alphabet"]
        # - noparam: Only trim the trailing parameters behind the character '?'
        # - alphabet: Trim the trailing parameters and Convert the segments
        #             containing non-alphabetical characters to star(*)
        url_clustering_method: alphabet
        # If the destination port of data is one of the followings, the protocol of such network request
        # is set to the corresponding one. Note the program will try to identify the protocol automatically
        # for the ports that are not in the lists, in which case the cpu usage will be increased much inevitably.
        protocol_config:
          - key: "http"
            ports: [ 80 ]
            # payload_length indicates the maximum size that payload can be fetched for target protocol
            # The trace data sent may contain such payload, so the higher this value, the larger network traffic.
            payload_length: 200
            slow_threshold: 500
          # The Dubbo parser is experimental now, so it is disabled by default. You could enable it by adding it
          # to the "protocol_parser" array.
          - key: "dubbo"
            payload_length: 200
          - key: "mysql"
            ports: [ 3306 ]
            slow_threshold: 100
            disable_discern: false
          - key: "kafka"
            ports: [ 9092 ]
            slow_threshold: 100
          - key: "redis"
            ports: [ 6379 ]
            slow_threshold: 100
          - key: "dns"
            ports: [ 53 ]
            slow_threshold: 100

    processors:
      k8smetadataprocessor:
        kube_auth_type: serviceAccount
        kube_config_dir: /root/.kube/config
        grace_delete_period: 60
      aggregateprocessor:
        # Aggregation duration window size. The unit is second.
        ticker_interval: 5
        aggregate_kind_map:
          request_total_time:
            - kind: sum
            - kind: avg
              output_name: request_total_time_avg
            - kind: count
              output_name: request_count
          request_io:
            - kind: sum
          response_io:
            - kind: sum
          kindling_tcp_rtt_microseconds:
            - kind: last
          kindling_tcp_retransmit_total:
            - kind: sum
          kindling_tcp_packet_loss_total:
            - kind: sum
          kindling_tcp_connect_total:
            - kind: sum
          kindling_tcp_connect_duration_nanoseconds_total:
            - kind: sum
        sampling_rate:
          normal_data: 0
          slow_data: 100
          error_data: 100

    exporters:
      otelexporter:
        adapter_config:
          need_trace_as_metric: true
          need_pod_detail: true
          store_external_src_ip: true
          # When using otlp-grpc / stdout exporter , this option supports to
          # send trace data in the format of ResourceSpan
          need_trace_as_span: false
        metric_aggregation_map:
          kindling_entity_request_total: counter
          kindling_entity_request_duration_nanoseconds_total: counter
          kindling_entity_request_send_bytes_total: counter
          kindling_entity_request_receive_bytes_total: counter
          kindling_topology_request_total: counter
          kindling_topology_request_duration_nanoseconds_total: counter
          kindling_topology_request_request_bytes_total: counter
          kindling_topology_request_response_bytes_total: counter
          kindling_trace_request_duration_nanoseconds: gauge
          kindling_tcp_srtt_microseconds: gauge
          kindling_tcp_retransmit_total: counter
          kindling_tcp_packet_loss_total: counter
          kindling_tcp_connect_total: counter
          kindling_tcp_connect_duration_nanoseconds_total: counter
        # Export data in the following ways: ["prometheus", "otlp", "stdout"]
        # Note: configure the corresponding section to make everything ok
        export_kind: prometheus
        # Add labels to all metrics in the format of [key: value]
        custom_labels:
        prometheus:
          port: :9500
        otlp:
          collect_period: 15s
          # Note: DO NOT add the prefix "http://"
          endpoint: 10.10.10.10:8080
        stdout:
          collect_period: 15s

    observability:
      logger:
        console_level: info # debug,info,warn,error,none
        file_level: info
        file_rotation:
          filename: agent.log
          maxsize: 512 #MB
          maxage: 30 #day
          maxbackups: 5
          localtime: true
          compress: false
      opentelemetry:
        # Export data in the following ways: ["prometheus", "otlp", "stdout"]
        # Note: configure the corresponding section to make everything ok
        export_kind: stdout
        prometheus:
          port: :9501
          # Self-metrics for special purpose
          # "resource" for agent CPU and memory usage metricss
          # extra_metrics: ["resource"]
        otlp:
          collect_period: 15s
          # Note: DO NOT add the prefix "http://"
          endpoint: 10.10.10.10:8080
        stdout:
          collect_period: 15s
